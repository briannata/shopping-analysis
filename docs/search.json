[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Amazon Shopping Analysis",
    "section": "",
    "text": "1 Introduction\nWe are exploring shopping habits in the United States, specifically purchases on Amazon from 2018 to 2023. Amazon is the largest online retailer so analyzing its shopping trends gives us insight into people’s needs and wants.\nWe are interested in exploring how the COVID-19 pandemic influenced online shopping trends, particularly how much people spent and what products were the most popular. This dataset has data from before, during and after the pandemic, allowing us to get a better understanding and comparison about how the pandemic affected people’s shopping habits.\nWe also want to analyze when is the most popular time to conduct online shopping, especially the date and time. We are particularly interested in seeing whether these trends correlate with major holidays, such as Christmas, or major sale events, like Black Friday and Prime Day.\nAs for general trends, we want to investigate what are the most popular products and categories for both the whole United States, and for each state. We also want to explore whether demographics (gender, race, sexual orientation, and age) have any correlation with shopping habits. We are also interested in exploring whether income, substance abuse, and education affects people’s spending habits and has any correlation with the kinds of products they purchase on Amazon. It would also be intriguing to see if personal situations, such as having diabetes or using a wheelchair, also affects an individual’s online shopping.\nIn general, we are excited to dive into US Amazon trends and explore what variables have correlations with a person’s shopping habits.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nIdentify one or more data sources (see II. D. above) that you propose to draw on for the project. For each, describe how the data are collected and by whom. Describe the format of the data, the frequency of updates, dimensions, and any other relevant information. Note any issues / problems with the data, either known or that you discover. Explain how you plan to import the data. Carefully document your sources with links to the precise data sources that you used. If that is not possible (for example if your data is not available online, then explain that clearly.) (suggested: 1/2 page)\nThere are two datasets, amazon_purchases.csv and survey.csv, from the Harvard paper, “Open e-commerce 1.0: Five years of crowdsourced U.S. Amazon purchase histories with user demographics.” The first dataset was a longitudinal collection of purchase data from 5027 Amazon.com users recruited from the online research platforms, Prolific and CloudResearch. If the user decided to share their data with the Harvard researchers, the data was included in the amazon_purchases.csv dataset. If the user then chose to answer an additional survey about their demographics and additional questions, they were compensated for their participation in this study. All participants had to be 18 years or older, U.S. resident and English speaker, and have an active Amazon account. The data collectors were researchers Alex Berke, Robert Mahari, Sandy Pentland, Kent Larson, and Dana Calacci, affiliated with Harvard, MIT and Penn State. This was a one time study so the data collection is finalized so there are not any updates.\nThe amazon_purchases dataset is a csv file with 1048576 rows and 7 columns while the survey dataset is 5028 rows and 23 columns. There is a common column of participant id, so we will join the two datasets together to get the full picture of the participant’s amazon purchases and survey responses, which will result in a dataset with a total of 1048576 rows and 30 columns. There is missing data for some of the shipping locations, item names (title) etc. which we will have to decide how to deal with that. However, for one of the survey questions there are blank responses to represent non applicable, so we need to distinguish this difference somehow.\nWe will import the data by downloading the csv that was included in the paper. We also have access to their github in case that is useful.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Data sources:\nDataset Source\nTheir github",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\nWe decided to look at the missing values for the datasets separately for this step before joining them for data analysis later on.\nImports\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.1\n\n\nCode\nlibrary(readr)\n\n\nWarning: package 'readr' was built under R version 4.4.1\n\n\nCode\nlibrary(naniar)\n\n\nWarning: package 'naniar' was built under R version 4.4.2\n\n\nLoad the amazon purchases data into a dataframe\n\n\nCode\namazon_purchases &lt;- read_csv(\"data/amazon-purchases.csv\")\n\n\nRows: 1850717 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): Shipping Address State, Title, ASIN/ISBN (Product Code), Category,...\ndbl  (2): Purchase Price Per Unit, Quantity\ndate (1): Order Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\noptions(readr.show_col_types = FALSE)\n\n\nSee how many missing values there are in each column\n\n\nCode\nprint(\"Missing values:\")\n\n\n[1] \"Missing values:\"\n\n\nCode\nmissing_values = colSums(is.na(amazon_purchases))\nprint(missing_values)\n\n\n              Order Date  Purchase Price Per Unit                 Quantity \n                       0                        0                        0 \n  Shipping Address State                    Title ASIN/ISBN (Product Code) \n                   87812                    89740                      973 \n                Category        Survey ResponseID \n                   89458                        0 \n\n\nGraph the missing values using the naniar package’s vis_miss function\n\n\nCode\nvis_miss(amazon_purchases, warn_large_data = FALSE)  +\n  labs(\n    title = \"Missing Data Visualization for Amazon Purchase Columns\",\n    x = \"Columns\",\n    y = \"Observations\"\n  )\n\n\n\n\n\n\n\n\n\nWe chose this graph to show the patterns in the missing values in each of the columns. We noticed that observations that had one column value missing did not necessarily have missing values in other columns. There didn’t seem to be a lot of overlap, and the missing values seemed to be random and have no pattern. Shipping address state, title, and category had about 5% of their data values missing, while ASIN/ISBN had less than 0.1% missing values.\nGraph the missing values as a simple bar graph to compare which columns have the most missing values\n\n\nCode\nmissing = setNames(nm=c('colnames', 'missing'),stack(colSums(is.na(amazon_purchases)))[2:1])\n\nggplot(missing, aes(x=colnames, y=missing)) + geom_bar(stat=\"identity\") +ggtitle(\"Distribution of Missing Values by Column Name for Amazon Purchases\") + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + xlab(\"Columns\") + ylab(\"Number of Missing Values\")\n\n\n\n\n\n\n\n\n\nWe noticed that shipping address state, title, and category had approximately the same amount of missing values. ASIN/ISBN had a very small amount of missing values, while the rest of the columns had no missing values.\nLoad in the survey dataset as a dataframe\n\n\nCode\nsurvey &lt;- read_csv(\"data/survey.csv\")\n\n\nPrint out the missing values per column in this dataset\n\n\nCode\nprint(\"Missing values:\")\n\n\n[1] \"Missing values:\"\n\n\nCode\nprint(colSums(is.na(survey)))\n\n\n         Survey ResponseID                Q-demos-age \n                         0                          0 \n          Q-demos-hispanic               Q-demos-race \n                         0                          0 \n         Q-demos-education             Q-demos-income \n                         0                          0 \n            Q-demos-gender       Q-sexual-orientation \n                         0                          0 \n             Q-demos-state       Q-amazon-use-howmany \n                         0                          0 \n      Q-amazon-use-hh-size       Q-amazon-use-how-oft \n                         0                          0 \nQ-substance-use-cigarettes  Q-substance-use-marijuana \n                         0                          0 \n   Q-substance-use-alcohol        Q-personal-diabetes \n                         0                          0 \n     Q-personal-wheelchair             Q-life-changes \n                         0                       3384 \n          Q-sell-YOUR-data       Q-sell-consumer-data \n                         0                          0 \n           Q-small-biz-use               Q-census-use \n                         0                          0 \n        Q-research-society \n                         0 \n\n\nQ-life-changes is the only column that has missing values in this survey dataset. This question is optional, which is why we expected to see this pattern of missing values for only this column.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\nlibrary(readr)\n\n\nWarning: package 'readr' was built under R version 4.4.1\n\n\nCode\npurchase = read_csv(\"data/amazon-purchases.csv\")\n\n\nRows: 1850717 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): Shipping Address State, Title, ASIN/ISBN (Product Code), Category,...\ndbl  (2): Purchase Price Per Unit, Quantity\ndate (1): Order Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nsurvey = read_csv(\"data/survey.csv\")\n\n\nRows: 5027 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (23): Survey ResponseID, Q-demos-age, Q-demos-hispanic, Q-demos-race, Q-...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# joined_df = merge(purchase, survey, by = \"Survey ResponseID\")\n# write.csv(joined_df, \"data/joined-amazon-purchases.csv\")\n\njoined_df = read_csv(\"data/joined-amazon-purchases.csv\")\n\n\nNew names:\nRows: 1850717 Columns: 31\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(27): Survey ResponseID, Shipping Address State, Title, ASIN/ISBN (Prod... dbl\n(3): ...1, Purchase Price Per Unit, Quantity date (1): Order Date\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\n\n4 Graph 1\n\n\nCode\nlibrary(dplyr)\n\n\nWarning: package 'dplyr' was built under R version 4.4.1\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.1\n\n\nCode\nlibrary(maps)\n\n\nWarning: package 'maps' was built under R version 4.4.2\n\n\nCode\n# Calculate the total number of purchases in each state\ntotal_purchases_by_state &lt;- joined_df %&gt;%\n  group_by(`Q-demos-state`) %&gt;%\n  summarise(total_purchases = n()) %&gt;%\n  mutate(`Q-demos-state` = tolower(`Q-demos-state`)) %&gt;%\n  arrange(desc(total_purchases))\n\n# View the resulting dataframe\nprint(total_purchases_by_state)\n\n\n# A tibble: 52 × 2\n   `Q-demos-state` total_purchases\n   &lt;chr&gt;                     &lt;int&gt;\n 1 california               192086\n 2 texas                    139562\n 3 florida                  114839\n 4 new york                 105414\n 5 pennsylvania             103237\n 6 ohio                      88496\n 7 north carolina            78065\n 8 illinois                  77178\n 9 michigan                  61401\n10 georgia                   59739\n# ℹ 42 more rows\n\n\nCode\n# Load map data for states\nstates &lt;- map_data(\"state\")\n\n# Join the purchase data with map data\nstates_purchases &lt;- states %&gt;%\n  rename(`Q-demos-state` = region) %&gt;%\n  left_join(total_purchases_by_state, by = \"Q-demos-state\")\n\n# Plot the data on a map\nggplot(states_purchases, aes(long, lat, group = group, fill = total_purchases)) +\n  geom_polygon(color = \"black\") +\n  scale_fill_viridis_c(option = \"magma\", na.value = \"gray\", direction = -1) +\n  theme_minimal() +\n  labs(title = \"Total Amazon Purchases from 2018 to 2023 by State\", fill = \"Total Purchases\")\n\n\n\n\n\n\n\n\n\n\n\n5 Graph 2\n\n\nCode\nlibrary(RColorBrewer)\n\n# Convert Order Date to Date type\npurchase$`Order Date` &lt;- as.Date(purchase$`Order Date`, format=\"%Y-%m-%d\")\n\n# Extract Year from Order Date\npurchase$Year &lt;- format(purchase$`Order Date`, \"%Y\")\n\n# Group by Year and Category to count purchases\ncategory_counts &lt;- purchase %&gt;%\n  group_by(Year, Category) %&gt;%\n  summarise(purchases = n()) %&gt;%\n  ungroup()\n\n\n`summarise()` has grouped output by 'Year'. You can override using the\n`.groups` argument.\n\n\nCode\n# Remove 'NA' categories and filter out the year 2024\ncategory_counts &lt;- category_counts %&gt;%\n  filter(Category != \"NA\" & Year != \"2024\")\n\n# Get the top 5 most purchased categories for each year\ntop_categories &lt;- category_counts %&gt;%\n  group_by(Year) %&gt;%\n  top_n(5, purchases) %&gt;%\n  ungroup()\n\n# Order categories within each year by number of purchases (tallest to shortest)\ntop_categories$Category &lt;- factor(top_categories$Category, \n                                   levels = top_categories %&gt;%\n                                     group_by(Year) %&gt;%\n                                     arrange(Year, desc(purchases)) %&gt;%\n                                     pull(Category) %&gt;%\n                                     unique())\n\n# Choose a qualitative color palette\npalette &lt;- brewer.pal(8, \"Set2\")\n\n# Create the grouped bar graph\nggplot(top_categories, aes(x = Year, y = purchases, fill = Category)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Top 5 Most Purchased Amazon Categories by Year\",\n       x = \"Year\", y = \"Number of Purchases\") +\n  scale_fill_manual(values = palette) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n6 Graph 3\n\n\nCode\n# Calculate total spending per user\nuser_spending &lt;- joined_df %&gt;%\n  mutate(Total_Spent = `Purchase Price Per Unit` * Quantity) %&gt;%\n  group_by(`Survey ResponseID`) %&gt;%\n  summarise(Total_Spent_Per_User = sum(Total_Spent, na.rm = TRUE))\n\n# Plot a histogram of total spending per user\nggplot(user_spending, aes(x = Total_Spent_Per_User)) +\n  geom_histogram(binwidth = 1000, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribution of Total Spending from 2018 to 2023 Per Account\",\n    x = \"Total Spending (USD)\",\n    y = \"Number of Accounts\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  }
]