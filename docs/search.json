[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Amazon Shopping Analysis",
    "section": "",
    "text": "1 Introduction\nWe are exploring shopping habits in the United States, specifically purchases on Amazon from 2018 to 2023. Amazon is the largest online retailer so analyzing its shopping trends gives us insight into people’s needs and wants.\nWe are interested in exploring how the COVID-19 pandemic influenced online shopping trends, particularly how much people spent and what products were the most popular. This dataset has data from before, during and after the pandemic, allowing us to get a better understanding and comparison about how the pandemic affected people’s shopping habits.\nWe also want to analyze when is the most popular time to conduct online shopping, especially the date and time. We are particularly interested in seeing whether these trends correlate with major holidays, such as Christmas, or major sale events, like Black Friday and Prime Day.\nAs for general trends, we want to investigate what are the most popular products and categories for both the whole United States, and for each state. We also want to explore whether demographics (gender, race, sexual orientation, and age) have any correlation with shopping habits. We are also interested in exploring whether income, substance abuse, and education affects people’s spending habits and has any correlation with the kinds of products they purchase on Amazon. It would also be intriguing to see if personal situations, such as having diabetes or using a wheelchair, also affects an individual’s online shopping.\nIn general, we are excited to dive into US Amazon trends and explore what variables have correlations with a person’s shopping habits.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nIdentify one or more data sources (see II. D. above) that you propose to draw on for the project. For each, describe how the data are collected and by whom. Describe the format of the data, the frequency of updates, dimensions, and any other relevant information. Note any issues / problems with the data, either known or that you discover. Explain how you plan to import the data. Carefully document your sources with links to the precise data sources that you used. If that is not possible (for example if your data is not available online, then explain that clearly.) (suggested: 1/2 page)\nThere are two datasets, amazon_purchases.csv and survey.csv, from the Harvard paper, “Open e-commerce 1.0: Five years of crowdsourced U.S. Amazon purchase histories with user demographics.” The first dataset was a longitudinal collection of purchase data from 5027 Amazon.com users recruited from the online research platforms, Prolific and CloudResearch. If the user decided to share their data with the Harvard researchers, the data was included in the amazon_purchases.csv dataset. If the user then chose to answer an additional survey about their demographics and additional questions, they were compensated for their participation in this study. All participants had to be 18 years or older, U.S. resident and English speaker, and have an active Amazon account. The data collectors were researchers Alex Berke, Robert Mahari, Sandy Pentland, Kent Larson, and Dana Calacci, affiliated with Harvard, MIT and Penn State. This was a one time study so the data collection is finalized so there are not any updates.\nThe amazon_purchases dataset is a csv file with 1048576 rows and 7 columns while the survey dataset is 5028 rows and 23 columns. There is a common column of participant id, so we will join the two datasets together to get the full picture of the participant’s amazon purchases and survey responses, which will result in a dataset with a total of 1048576 rows and 30 columns. There is missing data for some of the shipping locations, item names (title) etc. which we will have to decide how to deal with that. However, for one of the survey questions there are blank responses to represent non applicable, so we need to distinguish this difference somehow.\nWe will import the data by downloading the csv that was included in the paper. We also have access to their github in case that is useful.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Data sources:\nDataset Source\nTheir github",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\nWe decided to look at the missing values for the datasets separately for this step before joining them for data analysis later on.\nImports\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.1\n\n\nCode\nlibrary(readr)\n\n\nWarning: package 'readr' was built under R version 4.4.1\n\n\nCode\nlibrary(naniar)\n\n\nWarning: package 'naniar' was built under R version 4.4.2\n\n\nLoad the amazon purchases data into a dataframe\n\n\nCode\namazon_purchases &lt;- read_csv(\"data/amazon-purchases.csv\")\n\n\nRows: 1850717 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): Shipping Address State, Title, ASIN/ISBN (Product Code), Category,...\ndbl  (2): Purchase Price Per Unit, Quantity\ndate (1): Order Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\noptions(readr.show_col_types = FALSE)\n\n\nSee how many missing values there are in each column\n\n\nCode\nprint(\"Missing values:\")\n\n\n[1] \"Missing values:\"\n\n\nCode\nmissing_values = colSums(is.na(amazon_purchases))\nprint(missing_values)\n\n\n              Order Date  Purchase Price Per Unit                 Quantity \n                       0                        0                        0 \n  Shipping Address State                    Title ASIN/ISBN (Product Code) \n                   87812                    89740                      973 \n                Category        Survey ResponseID \n                   89458                        0 \n\n\nGraph the missing values using the naniar package’s vis_miss function\n\n\nCode\nvis_miss(amazon_purchases, warn_large_data = FALSE)  +\n  labs(\n    title = \"Missing Data Visualization for Amazon Purchase Columns\",\n    x = \"Columns\",\n    y = \"Observations\"\n  )\n\n\n\n\n\n\n\n\n\nWe chose this graph to show the patterns in the missing values in each of the columns. We noticed that observations that had one column value missing did not necessarily have missing values in other columns. There didn’t seem to be a lot of overlap, and the missing values seemed to be random and have no pattern. Shipping address state, title, and category had about 5% of their data values missing, while ASIN/ISBN had less than 0.1% missing values.\nGraph the missing values as a simple bar graph to compare which columns have the most missing values\n\n\nCode\nmissing = setNames(nm=c('colnames', 'missing'),stack(colSums(is.na(amazon_purchases)))[2:1])\n\nggplot(missing, aes(x=colnames, y=missing)) + geom_bar(stat=\"identity\") +ggtitle(\"Distribution of Missing Values by Column Name for Amazon Purchases\") + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + xlab(\"Columns\") + ylab(\"Number of Missing Values\")\n\n\n\n\n\n\n\n\n\nWe noticed that shipping address state, title, and category had approximately the same amount of missing values. ASIN/ISBN had a very small amount of missing values, while the rest of the columns had no missing values.\nLoad in the survey dataset as a dataframe\n\n\nCode\nsurvey &lt;- read_csv(\"data/survey.csv\")\n\n\nPrint out the missing values per column in this dataset\n\n\nCode\nprint(\"Missing values:\")\n\n\n[1] \"Missing values:\"\n\n\nCode\nprint(colSums(is.na(survey)))\n\n\n         Survey ResponseID                Q-demos-age \n                         0                          0 \n          Q-demos-hispanic               Q-demos-race \n                         0                          0 \n         Q-demos-education             Q-demos-income \n                         0                          0 \n            Q-demos-gender       Q-sexual-orientation \n                         0                          0 \n             Q-demos-state       Q-amazon-use-howmany \n                         0                          0 \n      Q-amazon-use-hh-size       Q-amazon-use-how-oft \n                         0                          0 \nQ-substance-use-cigarettes  Q-substance-use-marijuana \n                         0                          0 \n   Q-substance-use-alcohol        Q-personal-diabetes \n                         0                          0 \n     Q-personal-wheelchair             Q-life-changes \n                         0                       3384 \n          Q-sell-YOUR-data       Q-sell-consumer-data \n                         0                          0 \n           Q-small-biz-use               Q-census-use \n                         0                          0 \n        Q-research-society \n                         0 \n\n\nQ-life-changes is the only column that has missing values in this survey dataset. This question is optional, which is why we expected to see this pattern of missing values for only this column.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "3.1 State Map of Total Amazon Purchases\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(maps)\n\n# Calculate the total number of purchases in each state\ntotal_purchases_by_state &lt;- joined_df %&gt;%\n  group_by(`Q-demos-state`) %&gt;%\n  summarise(total_purchases = n()) %&gt;%\n  mutate(`Q-demos-state` = tolower(`Q-demos-state`)) %&gt;%\n  arrange(desc(total_purchases))\n\n# Load map data for states\nstates &lt;- map_data(\"state\")\n\n# Join the purchase data with map data\nstates_purchases &lt;- states %&gt;%\n  rename(`Q-demos-state` = region) %&gt;%\n  left_join(total_purchases_by_state, by = \"Q-demos-state\")\n\n# Plot the data on a map\nggplot(states_purchases, aes(long, lat, group = group, fill = total_purchases)) +\n  geom_polygon(color = \"black\") +\n  scale_fill_viridis_c(option = \"magma\", na.value = \"gray\", direction = -1) +\n  theme_minimal() +\n  labs(title = \"Total Amazon Purchases from 2018 to 2023 by State\", fill = \"Total Purchases\")\nWe used a US state map to visualize which states made the most Amazon purchases and which had the least from 2018 to 2023. California had the greatest amount of Amazon purchases by a large margin while Texas had the second highest. We were not surprised that California had the most purchases, but we were surprised that Texas was second. A lot of the midwest states, such as Montana, North Dakota, South Dakota, and Wyoming had the least amount of Amazon purchases.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#graph-2",
    "href": "results.html#graph-2",
    "title": "3  Results",
    "section": "3.2 Graph 2",
    "text": "3.2 Graph 2\n\n\nCode\nlibrary(RColorBrewer)\n\n# Convert Order Date to Date type\npurchase$`Order Date` &lt;- as.Date(purchase$`Order Date`, format=\"%Y-%m-%d\")\n\n# Extract Year from Order Date\npurchase$Year &lt;- format(purchase$`Order Date`, \"%Y\")\n\n# Group by Year and Category to count purchases\ncategory_counts &lt;- purchase %&gt;%\n  group_by(Year, Category) %&gt;%\n  summarise(purchases = n()) %&gt;%\n  ungroup()\n\n# Remove 'NA' categories and filter out the year 2024\ncategory_counts &lt;- category_counts %&gt;%\n  filter(Category != \"NA\" & Year != \"2024\")\n\n# Get the top 5 most purchased categories for each year\ntop_categories &lt;- category_counts %&gt;%\n  group_by(Year) %&gt;%\n  top_n(5, purchases) %&gt;%\n  ungroup()\n\n# Order categories within each year by number of purchases (tallest to shortest)\ntop_categories$Category &lt;- factor(top_categories$Category, \n                                   levels = top_categories %&gt;%\n                                     group_by(Year) %&gt;%\n                                     arrange(Year, desc(purchases)) %&gt;%\n                                     pull(Category) %&gt;%\n                                     unique())\n\n# Choose a qualitative color palette\npalette &lt;- brewer.pal(8, \"Set2\")\n\n# Create the grouped bar graph\nggplot(top_categories, aes(x = Year, y = purchases, fill = Category)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Top 5 Most Purchased Amazon Categories by Year\",\n       x = \"Year\", y = \"Number of Purchases\") +\n  scale_fill_manual(values = palette) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThis grouped bar chart shows the top purchases per year. For each year, books are consistently the top category purchased, followed by pet food. However, in 2022 and 2023, gift cards were no longer considered a top category and instead, medicine appeared. People also bought more nutritional supplements than shirts until 2021 and 2022, and then in 2023 nutritional supplements were more popular again.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#graph-3",
    "href": "results.html#graph-3",
    "title": "3  Results",
    "section": "3.3 Graph 3",
    "text": "3.3 Graph 3\n\n\nCode\n# Calculate total spending per user\nuser_spending &lt;- joined_df %&gt;%\n  mutate(Total_Spent = `Purchase Price Per Unit` * Quantity) %&gt;%\n  group_by(`Survey ResponseID`) %&gt;%\n  summarise(Total_Spent_Per_User = sum(Total_Spent, na.rm = TRUE))\n\n# Plot a histogram of total spending per user\nggplot(user_spending, aes(x = Total_Spent_Per_User)) +\n  geom_histogram(binwidth = 1000, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribution of Total Spending from 2018 to 2023 Per Account\",\n    x = \"Total Spending (USD)\",\n    y = \"Number of Accounts\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of user’s total spending over 5 years. The number of accounts is the frequency of Amazon users/accounts that spend that much over a total of 5 years. The majority of users spend less than $30,000 in 5 years, with the highest peak being $2,000 within 5 years. This histogram however is right skewed with some users spending almost $12,000 over the 5 year period. Knowing the distribution is skewed we may need to do something with our outliers when we use our data for our other visualizations.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#graph-4",
    "href": "results.html#graph-4",
    "title": "3  Results",
    "section": "3.4 Graph 4",
    "text": "3.4 Graph 4\n\n\nCode\nlibrary(ggalluvial)\n\n# Filter for rows where \"2023\" is in the \"Order Date\"\n# and find the top 5 categories by frequency\ntop_categories &lt;- joined_df %&gt;%\n  filter(grepl(\"2023\", `Order Date`)) %&gt;%\n  count(Category, sort = TRUE) %&gt;%\n  slice_max(n, n = 5) %&gt;%\n  pull(Category)\n\n# Filter the data for the top 5 categories\nalluvial_data &lt;- joined_df %&gt;%\n  filter(grepl(\"2023\", `Order Date`) & Category %in% top_categories) %&gt;%\n  select(`Q-demos-age`, Category, `Q-demos-income`) %&gt;%\n  filter(!is.na(`Q-demos-age`) & !is.na(Category) & !is.na(`Q-demos-income`))\n\n# Create the alluvial diagram\nggplot(alluvial_data,\n       aes(axis1 = `Q-demos-age`, axis2 = Category, axis3 = factor(`Q-demos-income`, levels = c(\"Less than $25,000\", \"$25,000 - $49,999\", \"$50,000 - $74,999\",\"$75,000 - $99,999\", \"$100,000 - $149,999\", \"$150,000 or more\", \"Prefer not to say\")))) +\n  geom_flow(aes(fill = Category)) +\n  geom_stratum(width = 0.6) +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 2.5) +\n  theme_minimal() +\n  labs(title = \"Alluvial Diagram of Age, Category, and Income for 2023\",\n       x = \"Variables\",\n       y = \"Frequency\") +\n  scale_x_discrete(labels = c(\"Age\", \"Category\", \"Income\")) +\n  theme(\n    legend.position = \"top\",            # Move legend to the top\n    legend.title = element_blank(),     # Optional: remove legend title for a cleaner look\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Optional: tilt axis labels\n    plot.margin = margin(10, 10, 10, 10)                # Reduce blank margins\n  )\n\n\n\n\n\n\n\n\n\nWe saw the top categories in the bar chart so now we are using an alluvial diagram to see the flow between the demographics, age and income, and the top 5 categories to find any trends or patterns. The book category has the most flow with the younger age groups buying more books on Amazon. This doesn’t mean that younger people read more and older people do not, it just shows that for this study these younger participants are buying more books online through Amazon. The second most frequent purchase category is pet food and we can see people from ages 24-54 are the top customers and usually they have a higher income. It was interesting to see that medication was the most popular for users between 24 and 44 years old with medium incomes at $25,000 - $74,999. This graph gave more insight into the interaction between variables when looking at the top categories.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#graph-5",
    "href": "results.html#graph-5",
    "title": "3  Results",
    "section": "3.5 Graph 5",
    "text": "3.5 Graph 5\n\n\nCode\nlibrary(vcd)\nsurvey = filter(survey, `Q-demos-gender` == 'Female' | `Q-demos-gender` == 'Male')\nsurvey = filter(survey, `Q-demos-education`!='Prefer not to say')\n\nsurvey = mutate(survey, `Q-demos-education` = ifelse(survey$`Q-demos-education`== \"Some High School or Less High School\" , \"&lt; High School\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Bachelor's degree\", \"Bachelors\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Graduate or professional degree (MA, MS, MBA, PhD, JD, MD, DDS, etc)\", \"Graduate\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Graduate/Professional Degree\", \"Graduate\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Some high school or less\", \"&lt;High School\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"High school diploma or GED\", \"High School\", survey$`Q-demos-education`))\nunique(survey$`Q-demos-education`)\n\n\n[1] \"High School\"  \"Graduate\"     \"Bachelors\"    \"&lt;High School\"\n\n\nCode\nsurvey = mutate(survey, `Q-amazon-use-how-oft` = ifelse(`Q-amazon-use-how-oft`== \"Less than 5 times per month\", \"&lt;5 a month\", survey$`Q-amazon-use-how-oft`))\nsurvey = mutate(survey, `Q-amazon-use-how-oft` = ifelse(`Q-amazon-use-how-oft`== \"5 - 10 times per month\", \"5-10 a month\", survey$`Q-amazon-use-how-oft`))\nsurvey = mutate(survey, `Q-amazon-use-how-oft` = ifelse(`Q-amazon-use-how-oft`== \"More than 10 times per month\", \"&gt;10 a month\", survey$`Q-amazon-use-how-oft`))\n\nvariables &lt;- c(\"Q-demos-gender\", \n               \"Q-amazon-use-how-oft\", \n               \"Q-demos-education\")\n\n# Filter the dataset to include only these variables\ndata_for_mosaic &lt;- survey %&gt;%\n  select(all_of(variables)) %&gt;%\n  na.omit() # Remove rows with NA values\n\n# Generate the mosaic plot\npairs(table(data_for_mosaic), \n      diag_panel = pairs_diagonal_mosaic(offset_varnames=-2.5),cex=1,\n      upper_panel_args = list(shade = TRUE),\n      lower_panel_args = list(shade = TRUE),\n      main = \"Mosaic Pairs Plot of Gender, Purchases per week, and High School education\")\n\n\n\n\n\n\n\n\n\nTo see if the variables have a strong association we used a mosaic plot. Gender and education levels were strongly associated. However, for our topic we are more interested in the association with how often the user purchases from Amazon a month (shopping frequency). When looking at all three variables together, they were not strongly associated. Then if we just look at gender and how often the user shops on Amazon, there appears to be more of an association compared to education level and shopping frequency.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#grouped-bar-chart-of-top-5-categories-per-year",
    "href": "results.html#grouped-bar-chart-of-top-5-categories-per-year",
    "title": "3  Results",
    "section": "3.2 Grouped Bar Chart of Top 5 Categories Per Year",
    "text": "3.2 Grouped Bar Chart of Top 5 Categories Per Year\n\n\nCode\nlibrary(RColorBrewer)\n\n# Convert Order Date to Date type\npurchase$`Order Date` &lt;- as.Date(purchase$`Order Date`, format=\"%Y-%m-%d\")\n\n# Extract Year from Order Date\npurchase$Year &lt;- format(purchase$`Order Date`, \"%Y\")\n\n# Group by Year and Category to count purchases\ncategory_counts &lt;- purchase %&gt;%\n  group_by(Year, Category) %&gt;%\n  summarise(purchases = n()) %&gt;%\n  ungroup()\n\n# Remove 'NA' categories and filter out the year 2024\ncategory_counts &lt;- category_counts %&gt;%\n  filter(Category != \"NA\" & Year != \"2024\")\n\n# Get the top 5 most purchased categories for each year\ntop_categories &lt;- category_counts %&gt;%\n  group_by(Year) %&gt;%\n  top_n(5, purchases) %&gt;%\n  ungroup()\n\n# Order categories within each year by number of purchases (tallest to shortest)\ntop_categories$Category &lt;- factor(top_categories$Category, \n                                   levels = top_categories %&gt;%\n                                     group_by(Year) %&gt;%\n                                     arrange(Year, desc(purchases)) %&gt;%\n                                     pull(Category) %&gt;%\n                                     unique())\n\n# Choose a qualitative color palette\npalette &lt;- brewer.pal(8, \"Set2\")\n\n# Create the grouped bar graph\nggplot(top_categories, aes(x = Year, y = purchases, fill = Category)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Top 5 Most Purchased Amazon Categories by Year\",\n       x = \"Year\", y = \"Number of Purchases\") +\n  scale_fill_manual(values = palette) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThis grouped bar chart shows the top purchases per year. For each year, books are consistently the top category purchased, followed by pet food. However, in 2022 and 2023, gift cards were no longer considered a top category and instead, medicine appeared. People also bought more nutritional supplements than shirts until 2021 and 2022, and then in 2023 nutritional supplements were more popular again.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#distribution-of-users-total-spending-on-amazon",
    "href": "results.html#distribution-of-users-total-spending-on-amazon",
    "title": "3  Results",
    "section": "3.3 Distribution of User’s Total Spending on Amazon",
    "text": "3.3 Distribution of User’s Total Spending on Amazon\n\n\nCode\n# Calculate total spending per user\nuser_spending &lt;- joined_df %&gt;%\n  mutate(Total_Spent = `Purchase Price Per Unit` * Quantity) %&gt;%\n  group_by(`Survey ResponseID`) %&gt;%\n  summarise(Total_Spent_Per_User = sum(Total_Spent, na.rm = TRUE))\n\n# Plot a histogram of total spending per user\nggplot(user_spending, aes(x = Total_Spent_Per_User)) +\n  geom_histogram(binwidth = 1000, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribution of Total Spending from 2018 to 2023 Per Account\",\n    x = \"Total Spending (USD)\",\n    y = \"Number of Accounts\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of user’s total spending over 5 years. The number of accounts is the frequency of Amazon users/accounts that spend that much over a total of 5 years. The majority of users spend less than $30,000 in 5 years, with the highest peak being $2,000 within 5 years. This histogram however is right skewed with some users spending almost $12,000 over the 5 year period. Knowing the distribution is skewed we may need to do something with our outliers when we use our data for our other visualizations.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#alluvial-diagram-of-age-amazon-category-and-income-for-2023",
    "href": "results.html#alluvial-diagram-of-age-amazon-category-and-income-for-2023",
    "title": "3  Results",
    "section": "3.4 Alluvial Diagram of Age, Amazon Category, and Income for 2023",
    "text": "3.4 Alluvial Diagram of Age, Amazon Category, and Income for 2023\n\n\nCode\nlibrary(ggalluvial)\n\n# Filter for rows where \"2023\" is in the \"Order Date\"\n# and find the top 5 categories by frequency\ntop_categories &lt;- joined_df %&gt;%\n  filter(grepl(\"2023\", `Order Date`)) %&gt;%\n  count(Category, sort = TRUE) %&gt;%\n  slice_max(n, n = 5) %&gt;%\n  pull(Category)\n\n# Filter the data for the top 5 categories\nalluvial_data &lt;- joined_df %&gt;%\n  filter(grepl(\"2023\", `Order Date`) & Category %in% top_categories) %&gt;%\n  select(`Q-demos-age`, Category, `Q-demos-income`) %&gt;%\n  filter(!is.na(`Q-demos-age`) & !is.na(Category) & !is.na(`Q-demos-income`))\n\n# Create the alluvial diagram\nggplot(alluvial_data,\n       aes(axis1 = `Q-demos-age`, axis2 = Category, axis3 = factor(`Q-demos-income`, levels = c(\"Less than $25,000\", \"$25,000 - $49,999\", \"$50,000 - $74,999\",\"$75,000 - $99,999\", \"$100,000 - $149,999\", \"$150,000 or more\", \"Prefer not to say\")))) +\n  geom_flow(aes(fill = Category)) +\n  geom_stratum(width = 0.6) +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 2.5) +\n  theme_minimal() +\n  labs(title = \"Alluvial Diagram of Age, Category, and Income for 2023\",\n       x = \"Variables\",\n       y = \"Frequency\") +\n  scale_x_discrete(labels = c(\"Age\", \"Category\", \"Income\")) +\n  theme(\n    legend.position = \"top\",            # Move legend to the top\n    legend.title = element_blank(),     # Optional: remove legend title for a cleaner look\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Optional: tilt axis labels\n    plot.margin = margin(10, 10, 10, 10)                # Reduce blank margins\n  )\n\n\n\n\n\n\n\n\n\nWe saw the top categories in the bar chart so now we are using an alluvial diagram to see the flow between the demographics, age and income, and the top 5 categories to find any trends or patterns. The book category has the most flow with the younger age groups buying more books on Amazon. This doesn’t mean that younger people read more and older people do not, it just shows that for this study these younger participants are buying more books online through Amazon. The second most frequent purchase category is pet food and we can see people from ages 24-54 are the top customers and usually they have a higher income. It was interesting to see that medication was the most popular for users between 24 and 44 years old with medium incomes at $25,000 - $74,999. This graph gave more insight into the interaction between variables when looking at the top categories.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#mosiac-pairs-plot-of-gender-purchases-per-week-and-education",
    "href": "results.html#mosiac-pairs-plot-of-gender-purchases-per-week-and-education",
    "title": "3  Results",
    "section": "3.5 Mosiac Pairs Plot of Gender, Purchases Per Week, and Education",
    "text": "3.5 Mosiac Pairs Plot of Gender, Purchases Per Week, and Education\n\n\nCode\nlibrary(vcd)\nsurvey = filter(survey, `Q-demos-gender` == 'Female' | `Q-demos-gender` == 'Male')\nsurvey = filter(survey, `Q-demos-education`!='Prefer not to say')\n\nsurvey = mutate(survey, `Q-demos-education` = ifelse(survey$`Q-demos-education`== \"Some High School or Less High School\" , \"&lt; High School\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Bachelor's degree\", \"Bachelors\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Graduate or professional degree (MA, MS, MBA, PhD, JD, MD, DDS, etc)\", \"Graduate\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Graduate/Professional Degree\", \"Graduate\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"Some high school or less\", \"&lt;High School\", survey$`Q-demos-education`))\nsurvey = mutate(survey, `Q-demos-education` = ifelse(`Q-demos-education`== \"High school diploma or GED\", \"High School\", survey$`Q-demos-education`))\nunique(survey$`Q-demos-education`)\n\n\n[1] \"High School\"  \"Graduate\"     \"Bachelors\"    \"&lt;High School\"\n\n\nCode\nsurvey = mutate(survey, `Q-amazon-use-how-oft` = ifelse(`Q-amazon-use-how-oft`== \"Less than 5 times per month\", \"&lt;5 a month\", survey$`Q-amazon-use-how-oft`))\nsurvey = mutate(survey, `Q-amazon-use-how-oft` = ifelse(`Q-amazon-use-how-oft`== \"5 - 10 times per month\", \"5-10 a month\", survey$`Q-amazon-use-how-oft`))\nsurvey = mutate(survey, `Q-amazon-use-how-oft` = ifelse(`Q-amazon-use-how-oft`== \"More than 10 times per month\", \"&gt;10 a month\", survey$`Q-amazon-use-how-oft`))\n\nvariables &lt;- c(\"Q-demos-gender\", \n               \"Q-amazon-use-how-oft\", \n               \"Q-demos-education\")\n\n# Filter the dataset to include only these variables\ndata_for_mosaic &lt;- survey %&gt;%\n  select(all_of(variables)) %&gt;%\n  na.omit() # Remove rows with NA values\n\n# Generate the mosaic plot\npairs(table(data_for_mosaic), \n      diag_panel = pairs_diagonal_mosaic(offset_varnames=-2.5),cex=1,\n      upper_panel_args = list(shade = TRUE),\n      lower_panel_args = list(shade = TRUE),\n      main = \"Mosaic Pairs Plot of Gender, Purchases Per Week, and Education\")\n\n\n\n\n\n\n\n\n\nTo see if the variables have a strong association we used a mosaic plot. Gender and education levels were strongly associated. However, for our topic we are more interested in the association with how often the user purchases from Amazon a month (shopping frequency). When looking at all three variables together, they were not strongly associated. Then if we just look at gender and how often the user shops on Amazon, there appears to be more of an association compared to education level and shopping frequency.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  }
]